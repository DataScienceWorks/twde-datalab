{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "import gzip\n",
    "from fbprophet import Prophet\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = 'twde-datalab'\n",
    "train_key = 'raw/train.csv'\n",
    "test_key = 'raw/test.csv'\n",
    "items_key = 'raw/items.csv'\n",
    "def get_df(key):\n",
    "    obj = s3.Object(bucket,key)\n",
    "    data = obj.get()['Body'].read()\n",
    "    df = pd.read_csv(io.BytesIO(data), encoding='utf8')\n",
    "    print(df.shape)\n",
    "    return df\n",
    "def get_testdf(key):\n",
    "    obj = s3.Object(bucket,key)\n",
    "    data = obj.get()['Body'].read()\n",
    "    df = pd.read_csv(io.BytesIO(data), parse_dates=['date'], encoding='utf8')\n",
    "    print(df.shape)\n",
    "    return df\n",
    "def get_traindf(key):\n",
    "    obj = s3.Object(bucket,key)\n",
    "    data = obj.get()['Body'].read()\n",
    "    traindf = pd.read_csv(io.BytesIO(data), parse_dates=['date'],\n",
    "                        encoding='utf8',\n",
    "                    skiprows=range(1, 86672217) #Skip dates before 2016-08-01\n",
    "                    )\n",
    "    return traindf\n",
    "def get_test_good(train, test):\n",
    "    train_last_date = train.groupby(['item_nbr', 'store_nbr'])['date'].max().reset_index()\n",
    "    train_last_date.rename(columns={'date':'last_date'}, inplace=True)\n",
    "    train_good_item_store = train_last_date[train_last_date['last_date']>=pd.to_datetime('2016-08-01')][['item_nbr', 'store_nbr', 'last_date']]\n",
    "    test_item_store = test.groupby(['item_nbr', 'store_nbr'])['date'].size().reset_index()[['item_nbr', 'store_nbr']]\n",
    "    test_item_store_join_good = pd.merge(test_item_store, train_good_item_store, on=['item_nbr', 'store_nbr'], how='left')\n",
    "    test_item_store_good = test_item_store_join_good[test_item_store_join_good['last_date'].notnull()][['item_nbr', 'store_nbr']]\n",
    "    test_good=pd.merge(test_item_store_good, test, on=['item_nbr', 'store_nbr'], how='left')\n",
    "    return test_good\n",
    "def fill_missing_date(df, total_dates):\n",
    "    idx = df.iloc[-1:,0].values[0]\n",
    "    for d in set(total_dates)-set(df['date'].unique()): \n",
    "        idx+=1\n",
    "        df.loc[idx, ['date', 'item_nbr', 'store_nbr']]= [pd.to_datetime(d), int(df.iloc[0]['item_nbr']), int(df.iloc[0]['store_nbr'])]\n",
    "    return df\n",
    "def get_predictions_for_test_good(test_good, train):\n",
    "    total_dates = train['date'].unique()\n",
    "    result = pd.DataFrame(columns=['id', 'unit_sales'])\n",
    "    problem_pairs = []\n",
    "    for name, y in test_good.groupby(['item_nbr', 'store_nbr']):\n",
    "        item_nbr=name[0]\n",
    "        store_nbr = name[1]\n",
    "        df = train[(train.item_nbr==item_nbr)&(train.store_nbr==store_nbr)]\n",
    "        print(\"item_nbr :\",item_nbr,\"store_nbr :\", store_nbr, \"df :\", df.shape, df['date'].max())\n",
    "        CV_SIZE = 16 #if you make it bigger, fill missing dates in cv with 0 if any\n",
    "        TRAIN_SIZE = 365\n",
    "        total_dates = train['date'].unique()\n",
    "        df = fill_missing_date(df, total_dates)\n",
    "        df = df.sort_values(by=['date'])\n",
    "        X = df[-TRAIN_SIZE:]\n",
    "        print('Train on: {}'.format(X.shape))\n",
    "        X = X[['date','unit_sales']]\n",
    "        X.columns = ['ds', 'y']\n",
    "        m = Prophet(yearly_seasonality=True)\n",
    "        try: \n",
    "            m.fit(X)\n",
    "        except ValueError:\n",
    "            print(\"problem for this item store pair\")\n",
    "            problem_pairs.append((item_nbr, store_nbr))\n",
    "            continue           \n",
    "        future = m.make_future_dataframe(periods=CV_SIZE)\n",
    "        pred = m.predict(future)\n",
    "        data = pred[['ds','yhat']].tail(CV_SIZE)\n",
    "        data = pred[['ds','yhat']].merge(y, left_on='ds', right_on='date')\n",
    "        data['unit_sales'] = data['yhat'].fillna(0).clip(0, 999999)\n",
    "        result = result.append(data[['id', 'unit_sales']])\n",
    "        print(\"result\", result.shape)\n",
    "    return (result, problem_pairs)\n",
    "def get_full_predictions_for_test_good(test_good, train):\n",
    "    total_dates = train['date'].unique()\n",
    "    result = pd.DataFrame(columns=['id', 'unit_sales'])\n",
    "    problem_pairs = []\n",
    "    for name, y in test_good.groupby(['item_nbr', 'store_nbr']):\n",
    "        item_nbr=name[0]\n",
    "        store_nbr = name[1]\n",
    "        df = train[(train.item_nbr==item_nbr)&(train.store_nbr==store_nbr)]\n",
    "        CV_SIZE = 16 #if you make it bigger, fill missing dates in cv with 0 if any\n",
    "        TRAIN_SIZE = 365\n",
    "        total_dates = train['date'].unique()\n",
    "        df = fill_missing_date(df, total_dates)\n",
    "        df = df.sort_values(by=['date'])\n",
    "        X = df[-TRAIN_SIZE:]\n",
    "        X = X[['date','unit_sales']]\n",
    "        X.columns = ['ds', 'y']\n",
    "        m = Prophet(yearly_seasonality=True)\n",
    "        try: \n",
    "            m.fit(X)\n",
    "        except ValueError:\n",
    "            print(\"problem for this item store pair\", item_nbr)\n",
    "            problem_pairs.append((item_nbr, store_nbr))\n",
    "            continue           \n",
    "        future = m.make_future_dataframe(periods=CV_SIZE)\n",
    "        pred = m.predict(future)\n",
    "        data = pred.tail(CV_SIZE)\n",
    "        data = pred.merge(y, left_on='ds', right_on='date')\n",
    "        data['unit_sales'] = data['yhat'].fillna(0).clip(0, 999999)\n",
    "        result = result.append(data.loc[:, data.columns != 'ds'])\n",
    "        print(\"result\", result.shape)\n",
    "    return (result, problem_pairs)\n",
    "\n",
    "def save_s3(df, key):\n",
    "    csv_buffer = io.StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "    csv_buffer.seek(0)\n",
    "    gz_buffer = io.BytesIO()\n",
    "\n",
    "    with gzip.GzipFile(mode='w', fileobj=gz_buffer) as gz_file:\n",
    "        gz_file.write(bytes(csv_buffer.getvalue(), 'utf-8'))\n",
    "\n",
    "    s3_object = s3.Object(bucket, key)\n",
    "    s3_object.put(Body=gz_buffer.getvalue())\n",
    "def run_forecast(train, test_good, test_good_item_store, key_part, begin_i, end_i=None):\n",
    "    \"\"\"\n",
    "    it takes 1000 (item, store) pairs as one unit\n",
    "    For example, if test_good_item_store.shape[0] is 162720, then you can choose begin_i from 1 to 163 and \n",
    "    end_i greater than begin_i while leaving end_i=None for the last begin_i=163 or in case you want to run for all the rest\n",
    "    For example, you can distribute the computation among several ec2 instances\n",
    "    \"\"\"\n",
    "    for i in range(begin_i, end_i):\n",
    "        name = \"test_good_item_store\"+str(i)\n",
    "        test_good_item_store_part = test_good_item_store[(i-1)*1000:i*1000]\n",
    "        if end_i==None:\n",
    "            test_good_item_store_part = test_good_item_store[(i-1)*1000:]\n",
    "        test_good_part = pd.merge(test_good, test_good_item_store_part, on=['item_nbr', 'store_nbr'], how='inner')\n",
    "        test_result_part, problem_pairs_part = get_full_predictions_for_test_good(test_good_part, train)\n",
    "        print(i, test_result_part.shape)\n",
    "        save_s3(test_result_part, key_part +str(i)+'.csv.gz')\n",
    "def get_gzdf(key):\n",
    "    obj = s3.Object(bucket,key)\n",
    "    data = obj.get()['Body'].read()\n",
    "    df = pd.read_csv(io.BytesIO(data), compression='gzip')\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "def get_zipdf(key):\n",
    "    obj = s3.Object(bucket,key)\n",
    "    data = obj.get()['Body'].read()\n",
    "    df = pd.read_csv(io.BytesIO(data), compression='zip')\n",
    "    print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.vendored.requests.packages.urllib3.connectionpool:Starting new HTTPS connection (2): s3.eu-west-1.amazonaws.com\n",
      "INFO:botocore.vendored.requests.packages.urllib3.connectionpool:Resetting dropped connection: s3.eu-west-1.amazonaws.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3370464, 5)\n",
      "(4100, 4)\n"
     ]
    }
   ],
   "source": [
    "train = get_traindf(train_key)\n",
    "train.loc[train['unit_sales']<0, 'unit_sales']=0\n",
    "test = get_testdf(test_key)\n",
    "items = get_df(items_key)\n",
    "test_good = get_test_good(train, test)\n",
    "test_good_item_store = test_good.groupby(['item_nbr', 'store_nbr'])['date'].count().reset_index()[['item_nbr', 'store_nbr']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run prophet forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162720"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_good_item_store.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_forecast(train, test_good, test_good_item_store, 'forecast/test_clean_result', 1, 163)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.vendored.requests.packages.urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com\n",
      "INFO:botocore.vendored.requests.packages.urllib3.connectionpool:Starting new HTTPS connection (1): s3.eu-west-1.amazonaws.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15936, 24)\n",
      "(15984, 24)\n",
      "(16000, 24)\n",
      "(15952, 24)\n",
      "(16000, 24)\n",
      "(15952, 24)\n",
      "(15968, 24)\n",
      "(16000, 24)\n",
      "(15936, 24)\n",
      "(15952, 24)\n",
      "(15920, 24)\n",
      "(16000, 24)\n",
      "(16000, 24)\n",
      "(15984, 24)\n",
      "(15904, 24)\n",
      "(15984, 24)\n",
      "(15936, 24)\n",
      "(15984, 24)\n",
      "(15920, 24)\n",
      "(15952, 24)\n",
      "(15952, 24)\n",
      "(15968, 24)\n",
      "(15952, 24)\n",
      "(15984, 24)\n",
      "(15936, 24)\n",
      "(15984, 24)\n",
      "(15952, 24)\n",
      "(15968, 24)\n",
      "(15968, 24)\n",
      "(15984, 24)\n",
      "(16000, 24)\n",
      "(15776, 24)\n",
      "(15888, 24)\n",
      "(15952, 24)\n",
      "(15936, 24)\n",
      "(15936, 24)\n",
      "(15888, 24)\n",
      "(15904, 24)\n",
      "(15920, 24)\n",
      "(15888, 24)\n",
      "(15984, 24)\n",
      "(16000, 24)\n",
      "(15904, 24)\n",
      "(15920, 24)\n",
      "(15984, 24)\n",
      "(15984, 24)\n",
      "(15936, 24)\n",
      "(15968, 24)\n",
      "(16000, 24)\n",
      "(15984, 24)\n",
      "(15952, 24)\n",
      "(15824, 24)\n",
      "(16000, 24)\n",
      "(16000, 24)\n",
      "(15984, 24)\n",
      "(15952, 24)\n",
      "(15984, 24)\n",
      "(15920, 24)\n",
      "(15952, 24)\n",
      "(16000, 24)\n",
      "(15920, 24)\n",
      "(15920, 24)\n",
      "(15984, 24)\n",
      "(15984, 24)\n",
      "(15952, 24)\n",
      "(15984, 24)\n",
      "(15872, 24)\n",
      "(15984, 24)\n",
      "(15856, 24)\n",
      "(15968, 24)\n",
      "(15904, 24)\n",
      "(15952, 24)\n",
      "(16000, 24)\n",
      "(15840, 24)\n",
      "(15984, 24)\n",
      "(15968, 24)\n",
      "(15888, 24)\n",
      "(15984, 24)\n",
      "(16000, 24)\n",
      "(15936, 24)\n",
      "(15888, 24)\n",
      "(15712, 24)\n",
      "(15952, 24)\n",
      "(15984, 24)\n",
      "(15952, 24)\n",
      "(15936, 24)\n",
      "(15952, 24)\n",
      "(15984, 24)\n",
      "(16000, 24)\n",
      "(15952, 24)\n",
      "(15920, 24)\n",
      "(15856, 24)\n",
      "(15808, 24)\n",
      "(15840, 24)\n",
      "(15792, 24)\n",
      "(15936, 24)\n",
      "(15952, 24)\n",
      "(16000, 24)\n",
      "(15904, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.vendored.requests.packages.urllib3.connectionpool:Resetting dropped connection: s3.eu-west-1.amazonaws.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15952, 24)\n",
      "(15936, 24)\n",
      "(15968, 24)\n",
      "(16000, 24)\n",
      "(15968, 24)\n",
      "(15952, 24)\n",
      "(15984, 24)\n",
      "(16000, 24)\n",
      "(15952, 24)\n",
      "(15968, 24)\n",
      "(15984, 24)\n",
      "(16000, 24)\n",
      "(15920, 24)\n",
      "(15888, 24)\n",
      "(15776, 24)\n",
      "(15488, 24)\n",
      "(15776, 24)\n",
      "(15664, 24)\n",
      "(15952, 24)\n",
      "(15936, 24)\n",
      "(15920, 24)\n",
      "(15856, 24)\n",
      "(15904, 24)\n",
      "(15712, 24)\n",
      "(15712, 24)\n",
      "(15696, 24)\n",
      "(15936, 24)\n",
      "(15904, 24)\n",
      "(16000, 24)\n",
      "(15952, 24)\n",
      "(15952, 24)\n",
      "(15936, 24)\n",
      "(15936, 24)\n",
      "(15952, 24)\n",
      "(15952, 24)\n",
      "(15968, 24)\n",
      "(16000, 24)\n",
      "(15936, 24)\n",
      "(15952, 24)\n",
      "(15872, 24)\n",
      "(15968, 24)\n",
      "(15952, 24)\n",
      "(15984, 24)\n",
      "(15920, 24)\n",
      "(15952, 24)\n",
      "(15968, 24)\n",
      "(15984, 24)\n",
      "(16000, 24)\n",
      "(15920, 24)\n",
      "(15888, 24)\n",
      "(15808, 24)\n",
      "(15968, 24)\n",
      "(16000, 24)\n",
      "(15984, 24)\n",
      "(15808, 24)\n",
      "(15872, 24)\n",
      "(15904, 24)\n",
      "(16000, 24)\n",
      "(15968, 24)\n",
      "(15920, 24)\n",
      "(15888, 24)\n",
      "(15936, 24)\n",
      "(15872, 24)\n",
      "(9856, 24)\n"
     ]
    }
   ],
   "source": [
    "clean_result_keys = ['forecast/test_clean_result'+str(i)+'.csv.gz' for i in range(1, 164)]\n",
    "clean_frames = [ get_gzdf(key) for key in clean_result_keys ]\n",
    "clean_result = pd.concat(clean_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'id', 'item_nbr', 'onpromotion', 'seasonal', 'seasonal_lower',\n",
       "       'seasonal_upper', 'seasonalities', 'seasonalities_lower',\n",
       "       'seasonalities_upper', 'store_nbr', 'trend', 'trend_lower',\n",
       "       'trend_upper', 'unit_sales', 'weekly', 'weekly_lower', 'weekly_upper',\n",
       "       'yearly', 'yearly_lower', 'yearly_upper', 'yhat', 'yhat_lower',\n",
       "       'yhat_upper'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>seasonal</th>\n",
       "      <th>seasonal_lower</th>\n",
       "      <th>seasonal_upper</th>\n",
       "      <th>seasonalities</th>\n",
       "      <th>seasonalities_lower</th>\n",
       "      <th>seasonalities_upper</th>\n",
       "      <th>...</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>weekly</th>\n",
       "      <th>weekly_lower</th>\n",
       "      <th>weekly_upper</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yearly_lower</th>\n",
       "      <th>yearly_upper</th>\n",
       "      <th>yhat</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>125497040</td>\n",
       "      <td>96995.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.308822</td>\n",
       "      <td>-0.308822</td>\n",
       "      <td>-0.308822</td>\n",
       "      <td>-0.308822</td>\n",
       "      <td>-0.308822</td>\n",
       "      <td>-0.308822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646213</td>\n",
       "      <td>-0.447095</td>\n",
       "      <td>-0.447095</td>\n",
       "      <td>-0.447095</td>\n",
       "      <td>0.138274</td>\n",
       "      <td>0.138274</td>\n",
       "      <td>0.138274</td>\n",
       "      <td>0.646213</td>\n",
       "      <td>0.170156</td>\n",
       "      <td>1.165704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>125707694</td>\n",
       "      <td>96995.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.029850</td>\n",
       "      <td>0.029850</td>\n",
       "      <td>0.029850</td>\n",
       "      <td>0.029850</td>\n",
       "      <td>0.029850</td>\n",
       "      <td>0.029850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977416</td>\n",
       "      <td>-0.070507</td>\n",
       "      <td>-0.070507</td>\n",
       "      <td>-0.070507</td>\n",
       "      <td>0.100357</td>\n",
       "      <td>0.100357</td>\n",
       "      <td>0.100357</td>\n",
       "      <td>0.977416</td>\n",
       "      <td>0.454921</td>\n",
       "      <td>1.455963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>125918348</td>\n",
       "      <td>96995.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.205031</td>\n",
       "      <td>0.205031</td>\n",
       "      <td>0.205031</td>\n",
       "      <td>0.205031</td>\n",
       "      <td>0.205031</td>\n",
       "      <td>0.205031</td>\n",
       "      <td>...</td>\n",
       "      <td>1.145129</td>\n",
       "      <td>0.138249</td>\n",
       "      <td>0.138249</td>\n",
       "      <td>0.138249</td>\n",
       "      <td>0.066782</td>\n",
       "      <td>0.066782</td>\n",
       "      <td>0.066782</td>\n",
       "      <td>1.145129</td>\n",
       "      <td>0.625048</td>\n",
       "      <td>1.676324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>126129002</td>\n",
       "      <td>96995.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.423354</td>\n",
       "      <td>0.423354</td>\n",
       "      <td>0.423354</td>\n",
       "      <td>0.423354</td>\n",
       "      <td>0.423354</td>\n",
       "      <td>0.423354</td>\n",
       "      <td>...</td>\n",
       "      <td>1.355984</td>\n",
       "      <td>0.385720</td>\n",
       "      <td>0.385720</td>\n",
       "      <td>0.385720</td>\n",
       "      <td>0.037634</td>\n",
       "      <td>0.037634</td>\n",
       "      <td>0.037634</td>\n",
       "      <td>1.355984</td>\n",
       "      <td>0.851699</td>\n",
       "      <td>1.835655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>126339656</td>\n",
       "      <td>96995.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.139430</td>\n",
       "      <td>0.139430</td>\n",
       "      <td>0.139430</td>\n",
       "      <td>0.139430</td>\n",
       "      <td>0.139430</td>\n",
       "      <td>0.139430</td>\n",
       "      <td>...</td>\n",
       "      <td>1.064592</td>\n",
       "      <td>0.126504</td>\n",
       "      <td>0.126504</td>\n",
       "      <td>0.126504</td>\n",
       "      <td>0.012926</td>\n",
       "      <td>0.012926</td>\n",
       "      <td>0.012926</td>\n",
       "      <td>1.064592</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>1.583967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date         id  item_nbr  onpromotion  seasonal  seasonal_lower  \\\n",
       "0  2017-08-16  125497040   96995.0        False -0.308822       -0.308822   \n",
       "1  2017-08-17  125707694   96995.0        False  0.029850        0.029850   \n",
       "2  2017-08-18  125918348   96995.0        False  0.205031        0.205031   \n",
       "3  2017-08-19  126129002   96995.0        False  0.423354        0.423354   \n",
       "4  2017-08-20  126339656   96995.0        False  0.139430        0.139430   \n",
       "\n",
       "   seasonal_upper  seasonalities  seasonalities_lower  seasonalities_upper  \\\n",
       "0       -0.308822      -0.308822            -0.308822            -0.308822   \n",
       "1        0.029850       0.029850             0.029850             0.029850   \n",
       "2        0.205031       0.205031             0.205031             0.205031   \n",
       "3        0.423354       0.423354             0.423354             0.423354   \n",
       "4        0.139430       0.139430             0.139430             0.139430   \n",
       "\n",
       "      ...      unit_sales    weekly  weekly_lower  weekly_upper    yearly  \\\n",
       "0     ...        0.646213 -0.447095     -0.447095     -0.447095  0.138274   \n",
       "1     ...        0.977416 -0.070507     -0.070507     -0.070507  0.100357   \n",
       "2     ...        1.145129  0.138249      0.138249      0.138249  0.066782   \n",
       "3     ...        1.355984  0.385720      0.385720      0.385720  0.037634   \n",
       "4     ...        1.064592  0.126504      0.126504      0.126504  0.012926   \n",
       "\n",
       "   yearly_lower  yearly_upper      yhat  yhat_lower  yhat_upper  \n",
       "0      0.138274      0.138274  0.646213    0.170156    1.165704  \n",
       "1      0.100357      0.100357  0.977416    0.454921    1.455963  \n",
       "2      0.066782      0.066782  1.145129    0.625048    1.676324  \n",
       "3      0.037634      0.037634  1.355984    0.851699    1.835655  \n",
       "4      0.012926      0.012926  1.064592    0.550025    1.583967  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.vendored.requests.packages.urllib3.connectionpool:Resetting dropped connection: s3.eu-west-1.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "save_s3(clean_result, 'forecast/test_clean_result_total.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
