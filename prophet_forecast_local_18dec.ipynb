{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fbprophet import Prophet\n",
    "def load_data(data_path):\n",
    "    train = pd.read_csv('%s/train.csv' % data_path, parse_dates=['date'],\n",
    "                       skiprows=range(1, 86672217) #Skip dates before 2016-08-01\n",
    "                       )\n",
    "    train.loc[train['unit_sales']<0, 'unit_sales']=0\n",
    "    test = pd.read_csv('%s/test.csv' % data_path, parse_dates=['date'])\n",
    "    items = pd.read_csv('%s/items.csv' % data_path)\n",
    "    return train, test, items\n",
    "def get_test_good(train, test):\n",
    "    train_last_date = train.groupby(['item_nbr', 'store_nbr'])['date'].max().reset_index()\n",
    "    train_last_date.rename(columns={'date':'last_date'}, inplace=True)\n",
    "    train_good_item_store = train_last_date[train_last_date['last_date']>=pd.to_datetime('2016-08-01')][['item_nbr', 'store_nbr', 'last_date']]\n",
    "    test_item_store = test.groupby(['item_nbr', 'store_nbr'])['date'].size().reset_index()[['item_nbr', 'store_nbr']]\n",
    "    test_item_store_join_good = pd.merge(test_item_store, train_good_item_store, on=['item_nbr', 'store_nbr'], how='left')\n",
    "    test_item_store_good = test_item_store_join_good[test_item_store_join_good['last_date'].notnull()][['item_nbr', 'store_nbr']]\n",
    "    test_good=pd.merge(test_item_store_good, test, on=['item_nbr', 'store_nbr'], how='left')\n",
    "    return test_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data'\n",
    "train, test, items = load_data(data_path)\n",
    "test_good = get_test_good(train, test)\n",
    "test_good_item_store = test_good.groupby(['item_nbr', 'store_nbr'])['date'].count().reset_index()[['item_nbr', 'store_nbr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_date(df, total_dates=train['date'].unique()):\n",
    "    idx = df.iloc[-1:,0].values[0]\n",
    "    for d in set(total_dates)-set(df['date'].unique()): \n",
    "        idx+=1\n",
    "        df.loc[idx, ['date', 'item_nbr', 'store_nbr']]= [pd.to_datetime(d), int(df.iloc[0]['item_nbr']), int(df.iloc[0]['store_nbr'])]\n",
    "    return df\n",
    "def get_predictions_for_test_good(test_good, train):\n",
    "    total_dates = train['date'].unique()\n",
    "    result = pd.DataFrame(columns=['id', 'unit_sales'])\n",
    "    problem_pairs = []\n",
    "    for name, y in test_good.groupby(['item_nbr', 'store_nbr']):\n",
    "        item_nbr=name[0]\n",
    "        store_nbr = name[1]\n",
    "        df = train[(train.item_nbr==item_nbr)&(train.store_nbr==store_nbr)]\n",
    "        print(\"item_nbr :\",item_nbr,\"store_nbr :\", store_nbr, \"df :\", df.shape, df['date'].max())\n",
    "        CV_SIZE = 16 #if you make it bigger, fill missing dates in cv with 0 if any\n",
    "        TRAIN_SIZE = 365\n",
    "        total_dates = train['date'].unique()\n",
    "        df = fill_missing_date(df, total_dates)\n",
    "        df = df.sort_values(by=['date'])\n",
    "        X = df[-TRAIN_SIZE:]\n",
    "        print('Train on: {}'.format(X.shape))\n",
    "        X = X[['date','unit_sales']]\n",
    "        X.columns = ['ds', 'y']\n",
    "        m = Prophet(yearly_seasonality=True)\n",
    "        try: \n",
    "            m.fit(X)\n",
    "        except ValueError:\n",
    "            print(\"problem for this item store pair\")\n",
    "            problem_pairs.append((item_nbr, store_nbr))\n",
    "            continue           \n",
    "        future = m.make_future_dataframe(periods=CV_SIZE)\n",
    "        pred = m.predict(future)\n",
    "        data = pred[['ds','yhat']].tail(CV_SIZE)\n",
    "        data = pred[['ds','yhat']].merge(y, left_on='ds', right_on='date')\n",
    "        data['unit_sales'] = data['yhat'].fillna(0).clip(0, 999999)\n",
    "        result = result.append(data[['id', 'unit_sales']])\n",
    "        print(\"result\", result.shape)\n",
    "    return (result, problem_pairs)\n",
    "def get_full_predictions_for_test_good(test_good, train):\n",
    "    total_dates = train['date'].unique()\n",
    "    result = pd.DataFrame(columns=['id', 'unit_sales'])\n",
    "    problem_pairs = []\n",
    "    for name, y in test_good.groupby(['item_nbr', 'store_nbr']):\n",
    "        item_nbr=name[0]\n",
    "        store_nbr = name[1]\n",
    "        df = train[(train.item_nbr==item_nbr)&(train.store_nbr==store_nbr)]\n",
    "        CV_SIZE = 16 #if you make it bigger, fill missing dates in cv with 0 if any\n",
    "        TRAIN_SIZE = 365\n",
    "        total_dates = train['date'].unique()\n",
    "        df = fill_missing_date(df, total_dates)\n",
    "        df = df.sort_values(by=['date'])\n",
    "        X = df[-TRAIN_SIZE:]\n",
    "        X = X[['date','unit_sales']]\n",
    "        X.columns = ['ds', 'y']\n",
    "        m = Prophet(yearly_seasonality=True)\n",
    "        try: \n",
    "            m.fit(X)\n",
    "        except ValueError:\n",
    "            print(\"problem for this item store pair\", item_nbr)\n",
    "            problem_pairs.append((item_nbr, store_nbr))\n",
    "            continue           \n",
    "        future = m.make_future_dataframe(periods=CV_SIZE)\n",
    "        pred = m.predict(future)\n",
    "        data = pred.tail(CV_SIZE)\n",
    "        data = pred.merge(y, left_on='ds', right_on='date')\n",
    "        data['unit_sales'] = data['yhat'].fillna(0).clip(0, 999999)\n",
    "        result = result.append(data.loc[:, data.columns != 'ds'])\n",
    "        print(\"result\", result.shape)\n",
    "    return (result, problem_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinyang/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 19.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result (5, 24)\n"
     ]
    }
   ],
   "source": [
    "test_result_part, problem_pairs_part = get_full_predictions_for_test_good(test_good, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
